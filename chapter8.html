<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Software Testing | Software Engineering</title>
    <link rel="stylesheet" href="src/output.css">
</head>

<body class="baddie">
    <div class="progress-bar" id="progressBar"></div>
    <header class="bg-accent-light lg:fixed sm:sticky top-0 left-0 w-full shadow-md z-50 shadow-lg backdrop-blur-sm bg-opacity-95">
    <div class="mx-auto px-4 sm:px-6 lg:px-8 py-4 lg:py-5">
      <div class="flex flex-col lg:flex-row justify-between items-center gap-4">
        <!-- Logo Section -->
        <div class="flex items-center gap-3 animate-fade-in">
          <div class="logo-style">
            <span class="text-2xl sm:text-3xl">⚡</span>
          </div>
          <h2 class="text-xl sm:text-2xl lg:text-3xl xl:text-4xl font-display font-bold text-gray-800">
            Software Engineering
          </h2>
        </div>

        <!-- Navigation -->
        <nav class="navi">
          <a href="home.html" class="navtext">Home</a>
          <a href="chapter2.html" class="navtext">Software Processes</a>
          <a href="chapter8.html" class="navtext">Testing</a>
          <a href="chapter9.html" class="navtext">Evolution</a>
          <a href="chapter11.html" class="navtext">Dependability</a>
        </nav>
      </div>
    </div>
    <div class="h-1 bg-linear-to-r from-primary-600 to-accent-darker"></div>
  </header>
    <main class=" mx-auto px-4 lg:px-6 py-6 lg:py-8">
        <section class="bg-border section-mwa card-gradient lg:mt-22">
            <article>
                <h3 class="h3">Objectives</h3>
                <p class="text-base lg:text-lg leading-relaxed mb-4">The objective of this chapter is to introduce software testing and software testing processes. When you have read the chapter, you will:</p>
                <ul class="space-y-3 ml-6 list-disc marker:text-primary-600">
                    <li class="leading-relaxed">understand the stages of testing from testing, during development to acceptance testing by system customers;</li>
                    <li class="leading-relaxed">have been introduced to techniques that help you choose test cases that are geared to discovering program defects;</li>
                    <li class="leading-relaxed">understand test-first development, where you design tests before writing code and run these tests automatically;</li>
                    <li class="leading-relaxed">know the important differences between component, system, and release testing and be aware of user testing processes and techniques.</li>
                </ul>
            </article>
        </section>

        <section class="bg-border section-mwa card-gradient">
            <article>
                <h3 class="h3">Contents</h3>
                <div class="div-grid">
                    <a href="#1" class="nav-a">
                        <span class="font-bold text-primary-600">8.1</span> Development Testing
                    </a>
                    <a href="#2" class="nav-a">
                        <span class="font-bold text-primary-600">8.2</span> Test-Driven Development
                    </a>
                    <a href="#3" class="nav-a">
                        <span class="font-bold text-primary-600">8.3</span> Release Testing
                    </a>
                    <a href="#4" class="nav-a">
                        <span class="font-bold text-primary-600">8.4</span> User Testing
                    </a>
                </div>
            </article>
        </section>

        <hr class="border-t-2 border-primary-600/40 my-8">

        <section class="bg-border section-mwa card-gradient">
            <h1 class="h1">Software Testing</h1>
            <p class="text-base lg:text-lg leading-relaxed mb-6">
                Testing is intended to show that a program does what it is intended to do and to discover program defects before it is put into use. When you test software, you execute a program using artificial data. You check the results of the test run for errors, anomalies, or information about the program's non-functional attributes.
            </p>
            <ul class="ul-ap">
                <li class="leading-relaxed">To demonstrate to the developer and the customer that the software meets its requirements. For custom software, this means that there should be at least one test for every requirement in the requirements document. For generic software products, it means that there should be tests for all of the system features, plus combinations of these features, that will be incorporated in the product release.</li>
                <li class="leading-relaxed">To discover situations in which the behavior of the software is incorrect, undesirable, or does not conform to its specification. These are a consequence of software defects. Defect testing is concerned with rooting out undesirable system behavior such as system crashes, unwanted interactions with other systems, incorrect computations, and data corruption.</li>
            </ul>
        </section>

        <section id="1" class="bg-border section-mwa card-gradient">
            <h2 class="h2">
                <span class="text-primary-600">8.1</span> Development Testing
            </h2>
            <p class="text-base lg:text-lg leading-relaxed mb-6">
                Development testing includes all testing activities that are carried out by the team developing the system. The tester of the software is usually the programmer who developed that software, although this is not always the case. Some development processes use programmer/tester pairs where each programmer has an associated tester who develops tests and assists with the testing process. For critical systems, a more formal process may be used, with a separate testing group within the development team. They are responsible for developing tests and maintaining detailed records of test results.
            </p>
            <p class="text-base lg:text-lg leading-relaxed mb-4">During development, testing may be carried out at three levels of granularity:</p>
            <ol class="ol-ap">
                <li class="leading-relaxed"><span class="font-semibold text-primary-700">Unit testing</span>, where individual program units or object classes are tested. Unit testing should focus on testing the functionality of objects or methods.</li>
                <li class="leading-relaxed"><span class="font-semibold text-primary-700">Component testing</span>, where several individual units are integrated to create composite components. Component testing should focus on testing component interfaces.</li>
                <li class="leading-relaxed"><span class="font-semibold text-primary-700">System testing</span>, where some or all of the components in a system are integrated and the system is tested as a whole. System testing should focus on testing component interactions.</li>
            </ol>
            <p class="text-base lg:text-lg leading-relaxed mt-6">
                Development testing is primarily a defect testing process, where the aim of testing is to discover bugs in the software. It is therefore usually interleaved with debugging—the process of locating problems with the code and changing the program to fix these problems.
            </p>

            <article class="article-border">
                <h3 class="h3">
                    <span class="text-primary-600">8.1.1</span> Unit Testing
                </h3>
                <p class="leading-relaxed mb-4">
                    Unit testing is the process of testing program components, such as methods or object classes. Individual functions or methods are the simplest type of component. Your tests should be calls to these routines with different input parameters. You can use the approaches to test case design discussed in Section 8.1.2, to design the function or method tests.
                </p>
                <p class="leading-relaxed mb-3">When you are testing object classes, you should design your tests to provide coverage of all of the features of the object. This means that you should:</p>
                <ul class="ul-ap">
                    <li class="leading-relaxed">test all operations associated with the object;</li>
                    <li class="leading-relaxed">set and check the value of all attributes associated with the object;</li>
                    <li class="leading-relaxed">put the object into all possible states. This means that you should simulate all events that cause a state change.</li>
                </ul>
            </article>

            <article class="article-border">
                <h3 class="h3">
                    <span class="text-primary-600">8.1.2</span> Choosing Unit Test Cases
                </h3>
                <p class="leading-relaxed mb-4">
                    Testing is expensive and time consuming, so it is important that you choose effective unit test cases. Effectiveness, in this case, means two things:
                </p>
                <ol class="ol-ap">
                    <li class="leading-relaxed">The test cases should show that, when used as expected, the component that you are testing does what it is supposed to do.</li>
                    <li class="leading-relaxed">If there are defects in the component, these should be revealed by test cases.</li>
                </ol><br>
                <p class="leading-relaxed mb-4">
                    You should therefore write two kinds of test case. The first of these should reflect normal operation of a program and should show that the component works. For example, if you are testing a component that creates and initializes a new patient record, then your test case should show that the record exists in a database and that its fields have been set as specified. The other kind of test case should be based on testing experience of where common problems arise. It should use abnormal inputs to check that these are properly processed and do not crash the component.
                </p>
                <p class="leading-relaxed mb-3">I discuss two possible strategies here that can be effective in helping you choose test cases. These are:</p>
                <ol class="ol-ap">
                    <li class="leading-relaxed"><span class="font-semibold text-primary-700">Partition testing</span>, where you identify groups of inputs that have common characteristics and should be processed in the same way. You should choose tests from within each of these groups.</li>
                    <li class="leading-relaxed"><span class="font-semibold text-primary-700">Guideline-based testing</span>, where you use testing guidelines to choose test cases. These guidelines reflect previous experience of the kinds of errors that programmers often make when developing components.</li>
                </ol>
            </article>

            <article class="article-border">
                <h3 class="h3">
                    <span class="text-primary-600">8.1.3</span> Component Testing
                </h3>
                <p class="leading-relaxed mb-4">
                    Software components are often composite components that are made up of several interacting objects. For example, in the weather station system, the reconfiguration component includes objects that deal with each aspect of the reconfiguration. You access the functionality of these objects through the defined component interface. Testing composite components should therefore focus on showing that the component interface behaves according to its specification. You can assume that unit tests on the individual objects within the component have been completed.
                </p>
                <p class="leading-relaxed mb-3">There are different types of interface between program components and, consequently, different types of interface error that can occur:</p>
                <ol class="ol-ap">
                    <li class="leading-relaxed"><span class="italic">Parameter interfaces</span> - These are interfaces in which data or sometimes function references are passed from one component to another. Methods in an object have a parameter interface.</li>
                    <li class="leading-relaxed"><span class="italic">Shared memory interfaces</span> - These are interfaces in which a block of memory is shared between components. Data is placed in the memory by one subsystem and retrieved from there by other sub-systems. This type of interface is often used in embedded systems, where sensors create data that is retrieved and processed by other system components.</li>
                    <li class="leading-relaxed"><span class="italic">Procedural interfaces</span> - These are interfaces in which one component encapsulates a set of procedures that can be called by other components. Objects and reusable components have this form of interface.</li>
                    <li class="leading-relaxed"><span class="italic">Message passing interfaces</span> - These are interfaces in which one component requests a service from another component by passing a message to it. A return message includes the results of executing the service. Some object-oriented systems have this form of interface, as do client–server systems.</li>
                </ol>
            </article>

            <article class="article-border">
                <h3 class="h3">
                    <span class="text-primary-600">8.1.4</span> System Testing
                </h3>
                <p class="leading-relaxed mb-4">
                    System testing during development involves integrating components to create a version of the system and then testing the integrated system. System testing checks that components are compatible, interact correctly and transfer the right data at the right time across their interfaces. It obviously overlaps with component testing but there are two important differences:
                </p>
                <ol class="ol-ap">
                    <li class="leading-relaxed">During system testing, reusable components that have been separately developed and off-the-shelf systems may be integrated with newly developed components. The complete system is then tested.</li>
                    <li class="leading-relaxed">Components developed by different team members or groups may be integrated at this stage. System testing is a collective rather than an individual process. In some companies, system testing may involve a separate testing team with no involvement from designers and programmers.</li>
                </ol><br>
                <p class="leading-relaxed">
                    When you integrate components to create a system, you get emergent behavior. This means that some elements of system functionality only become obvious when you put the components together. This may be planned emergent behavior, which has to be tested. For example, you may integrate an authentication component with a component that updates information. You then have a system feature that restricts information updating to authorized users. Sometimes, however, the emergent behavior is unplanned and unwanted. You have to develop tests that check that the system is only doing what it is supposed to do.
                </p>
            </article>
        </section>

        <section id="2" class="bg-border section-mwa card-gradient">
            <h2 class="h2">
                <span class="text-primary-600">8.2</span> Test-Driven Development
            </h2>
            <p class="text-base lg:text-lg leading-relaxed mb-6">
                Test-driven development (TDD) is an approach to program development in which you interleave testing and code development. Essentially, you develop the code incrementally, along with a test for that increment. You don't move on to the next increment until the code that you have developed passes its test. Test-driven development was introduced as part of agile methods such as Extreme Programming. However, it can also be used in plan-driven development processes.
            </p>
            <p class="leading-relaxed mb-3">The fundamental TDD process involves these steps:</p>
            <ol class="ol-ap">
                <li class="leading-relaxed">You start by identifying the increment of functionality that is required. This should normally be small and implementable in a few lines of code.</li>
                <li class="leading-relaxed">You write a test for this functionality and implement this as an automated test. This means that the test can be executed and will report whether or not it has passed or failed.</li>
                <li class="leading-relaxed">You then run the test, along with all other tests that have been implemented. Initially, you have not implemented the functionality so the new test will fail. This is deliberate as it shows that the test adds something to the test set.</li>
                <li class="leading-relaxed">You then implement the functionality and re-run the test. This may involve refactoring existing code to improve it and add new code to what's already there.</li>
                <li class="leading-relaxed">Once all tests run successfully, you move on to implementing the next chunk of functionality.</li>
            </ol><br>
            <p class="text-base lg:text-lg leading-relaxed mb-6">
                An automated testing environment, such as the JUnit environment that supports Java program testing, is essential for TDD. As the code is developed in very small increments, you have to be able to run every test each time that you add functionality or refactor the program. Therefore, the tests are embedded in a separate program that runs the tests and invokes the system that is being tested. Using this approach, it is possible to run hundreds of separate tests in a few seconds.
            </p>
            <p class="leading-relaxed mb-3">As well as better problem understanding, other benefits of test-driven development are:</p>
            <ol class="ol-ap">
                <li class="leading-relaxed"><span class="italic font-semibold text-primary-700">Code coverage</span> - In principle, every code segment that you write should have at least one associated test. Therefore, you can be confident that all of the code in the system has actually been executed. Code is tested as it is written so defects are discovered early in the development process.</li>
                <li class="leading-relaxed"><span class="italic font-semibold text-primary-700">Regression testing</span> - A test suite is developed incrementally as a program is developed. You can always run regression tests to check that changes to the program have not introduced new bugs.</li>
                <li class="leading-relaxed"><span class="italic font-semibold text-primary-700">Simplified debugging</span> - When a test fails, it should be obvious where the problem lies. The newly written code needs to be checked and modified. You do not need to use debugging tools to locate the problem. Reports of the use of test-driven development suggest that it is hardly ever necessary to use an automated debugger in test-driven development.</li>
                <li class="leading-relaxed"><span class="italic font-semibold text-primary-700">System documentation</span> - The tests themselves act as a form of documentation that describe what the code should be doing. Reading the tests can make it easier to understand the code.</li>
            </ol><br>
            <p class="text-base lg:text-lg leading-relaxed mb-6">
                One of the most important benefits of test-driven development is that it reduces the costs of regression testing. Regression testing involves running test sets that have successfully executed after changes have been made to a system. The regression test checks that these changes have not introduced new bugs into the system and that the new code interacts as expected with the existing code. Regression testing is very expensive and often impractical when a system is manually tested, as the costs in time and effort are very high.
            </p>
            <p class="text-base lg:text-lg leading-relaxed mb-6">
                However, automated testing, which is fundamental to test-first development, dramatically reduces the costs of regression testing. Existing tests may be re-run quickly and cheaply. After making a change to a system in test-first development, all existing tests must run successfully before any further functionality is added. As a programmer, you can be confident that the new functionality that you have added has not caused or revealed problems with existing code.
            </p>
            <p class="text-base lg:text-lg leading-relaxed">
                Test-driven development has proved to be a successful approach for small and medium-sized projects. Generally, programmers who have adopted this approach are happy with it and find it a more productive way to develop software. In some trials, it has been shown to lead to improved code quality; in others, the results have been inconclusive. However, there is no evidence that TDD leads to poorer quality code.
            </p>
        </section>

        <section id="3" class="bg-border section-mwa card-gradient">
            <h2 class="h2">
                <span class="text-primary-600">8.3</span> Release Testing
            </h2>
            <p class="text-base lg:text-lg leading-relaxed mb-6">
                Release testing is the process of testing a particular release of a system that is intended for use outside of the development team. Normally, the system release is for customers and users. In a complex project, however, the release could be for other teams that are developing related systems. For software products, the release could be for product management who then prepare it for sale.
            </p>
            <p class="leading-relaxed mb-3">There are two important distinctions between release testing and system testing during the development process:</p>
            <ol class="ol-ap">
                <li class="leading-relaxed">A separate team that has not been involved in the system development should be responsible for release testing.</li>
                <li class="leading-relaxed">System testing by the development team should focus on discovering bugs in the system (defect testing). The objective of release testing is to check that the system meets its requirements and is good enough for external use (validation testing).</li>
            </ol><br>
            <p class="text-base lg:text-lg leading-relaxed mb-6">
                The primary goal of the release testing process is to convince the supplier of the system that it is good enough for use. If so, it can be released as a product or delivered to the customer. Release testing, therefore, has to show that the system delivers its specified functionality, performance, and dependability, and that it does not fail during normal use. It should take into account all of the system requirements, not just the requirements of the end-users of the system.
            </p>
            <p class="text-base lg:text-lg leading-relaxed">
                Release testing is usually a black-box testing process where tests are derived from the system specification. The system is treated as a black box whose behavior can only be determined by studying its inputs and the related outputs. Another name for this is 'functional testing', so-called because the tester is only concerned with functionality and not the implementation of the software.
            </p>

            <article class="article-border">
                <h3 class="h3">
                    <span class="text-primary-600">8.3.1</span> Requirements-Based Testing
                </h3>
                <p class="leading-relaxed mb-4">
                    A general principle of good requirements engineering practice is that requirements should be testable; that is, the requirement should be written so that a test can be designed for that requirement. A tester can then check that the requirement has been satisfied. Requirements-based testing, therefore, is a systematic approach to test case design where you consider each requirement and derive a set of tests for it. Requirements-based testing is validation rather than defect testing—you are trying to demonstrate that the system has properly implemented its requirements.
                </p>
                <p class="leading-relaxed mb-3">For example, consider related requirements for the MHC-PMS, which are concerned with checking for drug allergies:</p>
                <div class="bg-accent-light/30 border-l-4 border-primary-600 p-4 mb-4 rounded">
                    <p class="italic leading-relaxed mb-2">If a patient is known to be allergic to any particular medication, then prescription of that medication shall result in a warning message being issued to the system user.</p>
                    <p class="italic leading-relaxed">If a prescriber chooses to ignore an allergy warning, they shall provide a reason why this has been ignored.</p>
                </div>
                <p class="leading-relaxed mb-3">To check if these requirements have been satisfied, you may need to develop several related tests:</p>
                <ol class="ol-ap">
                    <li class="leading-relaxed">Set up a patient record with no known allergies. Prescribe medication for allergies that are known to exist. Check that a warning message is not issued by the system.</li>
                    <li class="leading-relaxed">Set up a patient record with a known allergy. Prescribe the medication to that the patient is allergic to, and check that the warning is issued by the system.</li>
                    <li class="leading-relaxed">Set up a patient record in which allergies to two or more drugs are recorded. Prescribe both of these drugs separately and check that the correct warning for each drug is issued.</li>
                    <li class="leading-relaxed">Prescribe two drugs that the patient is allergic to. Check that two warnings are correctly issued.</li>
                    <li class="leading-relaxed">Prescribe a drug that issues a warning and overrule that warning. Check that the system requires the user to provide information explaining why the warning was overruled.</li>
                </ol><br>
                <p class="leading-relaxed">
                    You can see from this that testing a requirement does not mean just writing a single test. You normally have to write several tests to ensure that you have coverage of the requirement. You should also maintain traceability records of your requirements-based testing, which link the tests to the specific requirements that are being tested.
                </p>
            </article>

            <article class="article-border">
                <h3 class="h3">
                    <span class="text-primary-600">8.3.2</span> Scenario Testing
                </h3>
                <p class="leading-relaxed mb-4">
                    Scenario testing is an approach to release testing where you devise typical scenarios of use and use these to develop test cases for the system. A scenario is a story that describes one way in which the system might be used. Scenarios should be realistic and real system users should be able to relate to them. If you have used scenarios as part of the requirements engineering process, then you may be able to reuse these as testing scenarios.
                </p>
                <p class="leading-relaxed mb-4">
                    In a short paper on scenario testing, Kaner suggests that a scenario test should be a narrative story that is credible and fairly complex. It should motivate stakeholders; that is, they should relate to the scenario and believe that it is important that the system passes the test. He also suggests that it should be easy to evaluate. If there are problems with the system, then the release testing team should recognize them.
                </p>
                <p class="leading-relaxed mb-3">It tests a number of features of the MHC-PMS:</p>
                <ol class="ol-ap">
                    <li class="leading-relaxed">Authentication by logging on to the system.</li>
                    <li class="leading-relaxed">Downloading and uploading of specified patient records to a laptop.</li>
                    <li class="leading-relaxed">Home visit scheduling.</li>
                    <li class="leading-relaxed">Encryption and decryption of patient records on a mobile device.</li>
                    <li class="leading-relaxed">Record retrieval and modification.</li>
                    <li class="leading-relaxed">Links with the drugs database that maintains side-effect information.</li>
                    <li class="leading-relaxed">The system for call prompting.</li>
                </ol><br>
                <p class="leading-relaxed">
                    When you use a scenario-based approach, you are normally testing several requirements within the same scenario. Therefore, as well as checking individual requirements, you are also checking that combinations of requirements do not cause problems.
                </p>
            </article>

            <article class="article-border">
                <h3 class="h3">
                    <span class="text-primary-600">8.3.3</span> Performance Testing
                </h3>
                <p class="leading-relaxed mb-4">
                    Once a system has been completely integrated, it is possible to test for emergent properties, such as performance and reliability. Performance tests have to be designed to ensure that the system can process its intended load. This usually involves running a series of tests where you increase the load until the system performance becomes unacceptable.
                </p>
                <p class="leading-relaxed mb-4">
                    This approach, of course, is not necessarily the best approach for defect testing. Experience has shown that an effective way to discover defects is to design tests around the limits of the system. In performance testing, this means stressing the system by making demands that are outside the design limits of the software. This is known as 'stress testing'. For example, say you are testing a transaction processing system that is designed to process up to 300 transactions per second. You start by testing this system with fewer than 300 transactions per second. You then gradually increase the load on the system beyond 300 transactions per second until it is well beyond the maximum design load of the system and the system fails. This type of testing has two functions:
                </p>
                <ol class="ol-ap">
                    <li class="leading-relaxed">It tests the failure behavior of the system. Circumstances may arise through an unexpected combination of events where the load placed on the system exceeds the maximum anticipated load. In these circumstances, it is important that system failure should not cause data corruption or unexpected loss of user services. Stress testing checks that overloading the system causes it to 'fail-soft' rather than collapse under its load.</li>
                    <li class="leading-relaxed">It stresses the system and may cause defects to come to light that would not normally be discovered. Although it can be argued that these defects are unlikely to cause system failures in normal usage, there may be unusual combinations of normal circumstances that the stress testing replicates.</li>
                </ol><br>
                <p class="leading-relaxed">
                    Stress testing is particularly relevant to distributed systems based on a network of processors. These systems often exhibit severe degradation when they are heavily loaded. The network becomes swamped with coordination data that the different processes must exchange. The processes become slower and slower as they wait for the required data from other processes. Stress testing helps you discover when the degradation begins so that you can add checks to the system to reject transactions beyond this point.
                </p>
            </article>
        </section>

        <section id="4" class="bg-border section-mwa card-gradient">
            <h2 class="h2">
                <span class="text-primary-600">8.4</span> User Testing
            </h2>
            <p class="text-base lg:text-lg leading-relaxed mb-6">
                User or customer testing is a stage in the testing process in which users or customers provide input and advice on system testing. This may involve formally testing a system that has been commissioned from an external supplier, or could be an informal process where users experiment with a new software product to see if they like it and that it does what they need. User testing is essential, even when comprehensive system and release testing have been carried out. The reason for this is that influences from the user's working environment have a major effect on the reliability, performance, usability, and robustness of a system.
            </p>
            <p class="text-base lg:text-lg leading-relaxed mb-6">
                It is practically impossible for a system developer to replicate the system's working environment, as tests in the developer's environment are inevitably artificial. For example, a system that is intended for use in a hospital is used in a clinical environment where other things are going on, such as patient emergencies, conversations with relatives, etc. These all affect the use of a system, but developers cannot include them in their testing environment.
            </p>
            <p class="leading-relaxed mb-3">In practice, there are three different types of user testing:</p>
            <ol class="ol-ap">
                <li class="leading-relaxed"><span class="font-semibold text-primary-700">Alpha testing</span>, where users of the software work with the development team to test the software at the developer's site.</li>
                <li class="leading-relaxed"><span class="font-semibold text-primary-700">Beta testing</span>, where a release of the software is made available to users to allow them to experiment and to raise problems that they discover with the system developers.</li>
                <li class="leading-relaxed"><span class="font-semibold text-primary-700">Acceptance testing</span>, where customers test a system to decide whether or not it is ready to be accepted from the system developers and deployed in the customer environment.</li>
            </ol><br>
            <p class="text-base lg:text-lg leading-relaxed mb-6">
                <span class="font-semibold text-primary-700">Alpha testing</span> is often used when developing software products that are sold as shrink-wrapped systems. Users of these products may be willing to get involved in the alpha testing process because this gives them early information about new system features that they can exploit. It also reduces the risk that unanticipated changes to the software will have disruptive effects on their business. However, alpha testing may also be used when custom software is being developed. Agile methods, such as XP, advocate user involvement in the development process and that users should play a key role in designing tests for the system.
            </p>
            <p class="text-base lg:text-lg leading-relaxed mb-6">
                <span class="font-semibold text-primary-700">Beta testing</span> takes place when an early, sometimes unfinished, release of a software system is made available to customers and users for evaluation. Beta testers may be a selected group of customers who are early adopters of the system. Alternatively, the software may be made publicly available for use by anyone who is interested in it. Beta testing is mostly used for software products that are used in many different environments (as opposed to custom systems which are generally used in a defined environment). It is impossible for product developers to know and replicate all the environments in which the software will be used. Beta testing is therefore essential to discover interaction problems between the software and features of the environment where it is used. Beta testing is also a form of marketing— customers learn about their system and what it can do for them.
            </p>
            <p class="text-base lg:text-lg leading-relaxed mb-6">
                <span class="font-semibold text-primary-700">Acceptance testing</span> is an inherent part of custom systems development. It takes place after release testing. It involves a customer formally testing a system to decide whether or not it should be accepted from the system developer. Acceptance implies that payment should be made for the system.
            </p>
            <p class="leading-relaxed mb-3">There are six stages in the acceptance testing process. They are:</p>
            <ol class="ol-ap">
                <li class="leading-relaxed"><span class="italic font-semibold text-primary-700">Define acceptance criteria</span> - This stage should, ideally, take place early in the process before the contract for the system is signed. The acceptance criteria should be part of the system contract and be agreed between the customer and the developer. In practice, however, it can be difficult to define criteria so early in the process. Detailed requirements may not be available and there may be significant requirements change during the development process.</li>
                <li class="leading-relaxed"><span class="italic font-semibold text-primary-700">Plan acceptance testing</span> - This involves deciding on the resources, time, and budget for acceptance testing and establishing a testing schedule. The acceptance test plan should also discuss the required coverage of the requirements and the order in which system features are tested. It should define risks to the testing process, such as system crashes and inadequate performance, and discuss how these risks can be mitigated.</li>
                <li class="leading-relaxed"><span class="italic font-semibold text-primary-700">Derive acceptance tests</span> - Once acceptance criteria have been established, tests have to be designed to check whether or not a system is acceptable. Acceptance tests should aim to test both the functional and non-functional characteristics (e.g., performance) of the system. They should, ideally, provide complete coverage of the system requirements. In practice, it is difficult to establish completely objective acceptance criteria. There is often scope for argument about whether or not a test shows that a criterion has definitely been met.</li>
                <li class="leading-relaxed"><span class="italic font-semibold text-primary-700">Run acceptance tests</span> - The agreed acceptance tests are executed on the system. Ideally, this should take place in the actual environment where the system will be used, but this may be disruptive and impractical. Therefore, a user testing environment may have to be set up to run these tests. It is difficult to automate this process as part of the acceptance tests may involve testing the interactions between end-users and the system. Some training of end-users may be required.</li>
                <li class="leading-relaxed"><span class="italic font-semibold text-primary-700">Negotiate test results</span> - It is very unlikely that all of the defined acceptance tests will pass and that there will be no problems with the system. If this is the case, then acceptance testing is complete and the system can be handed over. More commonly, some problems will be discovered. In such cases, the developer and the customer have to negotiate to decide if the system is good enough to be put into use. They must also agree on the developer's response to identified problems.</li>
                <li class="leading-relaxed"><span class="italic font-semibold text-primary-700">Reject/accept system</span> - This stage involves a meeting between the developers and the customer to decide on whether or not the system should be accepted. If the system is not good enough for use, then further development is required to fix the identified problems. Once complete, the acceptance testing phase is repeated.</li>
            </ol><br>
            <p class="text-base lg:text-lg leading-relaxed mb-6">
                In agile methods, such as XP, acceptance testing has a rather different meaning. In principle, it shares the notion that users should decide whether or not the system is acceptable. However, in XP, the user is part of the development team (i.e., he or she is an alpha tester) and provides the system requirements in terms of user stories. He or she is also responsible for defining the tests, which decide whether or not the developed software supports the user story. The tests are automated and development does not proceed until the story acceptance tests have passed. There is, therefore, no separate acceptance testing activity.
            </p>
            <p class="text-base lg:text-lg leading-relaxed">
                You might think that acceptance testing is a clear-cut contractual issue. If a system does not pass its acceptance tests, then it should not be accepted and payment should not be made. However, the reality is more complex. Customers want to use the software as soon as they can because of the benefits of its immediate deployment. They may have bought new hardware, trained staff, and changed their processes. They may be willing to accept the software, irrespective of problems, because the costs of not using the software are greater than the costs of working around the problems. Therefore, the outcome of negotiations may be conditional acceptance of the system. The customer may accept the system so that deployment can begin. The system provider agrees to repair urgent problems and deliver a new version to the customer as quickly as possible.
            </p>
        </section>
    </main>

    <hr class="border-t-2 border-primary-300/40 my-8">

    <footer class="bg-accent-light shadow-2xl mt-12">
    <div class="h-1 bg-linear-to-r from-primary-600 via-accent-darker to-accent-darker"></div>
    <div class=" mx-auto px-4 sm:px-6 lg:px-8 py-6">
      <div class="text-center">
        <p class="text-gray-800 font-semibold text-lg mb-2">&copy; 2025 Group 8 All rights reserved.</p>
        <div class="flex justify-center gap-3 flex-wrap">
          <p class="text-gray-700">ARIZALA, RON ANDREW |</p>
          <p class="text-gray-700">MANINGAT, NICOLL MITCH |</p>
          <p class="text-gray-700">LOPEZ, RANIEL CARL |</p>
          <p class="text-gray-700">DAYAO, BABY JOY</p>
        </div>

        <div class="mt-4 pt-4 border-t border-gray-400">
            <h4 class="text-gray-600">Software Engineering</h4>
          <p class="text-sm text-gray-600">
             Chapter 11 - Dependability and Security | Chapter 9 - Software Evolution | Chapter 8 - Software Testing  | Chapter 2 - Software Processes
          </p>
        </div>
      </div>
    </div>
  </footer>
</body>
</html>